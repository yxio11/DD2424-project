{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67a0dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/how-to-create-an-empty-tuple-in-python/\n",
    "\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), hidden_size).to(x.device)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "\n",
    "# input_size = 1\n",
    "# hidden_size = 20\n",
    "# output_size = 1\n",
    "# model = SimpleRNN(input_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03b11277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = mps\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f'Device = {device}')\n",
    "print(torch.backends.mps.is_available())\n",
    "print(torch.backends.mps.is_built())\n",
    "\n",
    "FILE_PATH = './shakes.txt'\n",
    "SEQ_LENGTH = 25\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "HIDDEN_SIZE = 256\n",
    "HIDDEN_LAYERS = 1\n",
    "\n",
    "NUM_EPOCHS = 1\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8beff39a",
   "metadata": {},
   "source": [
    "### Data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "096ba0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394\n",
      "65\n",
      "(65, 25)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "class DataPreprocessing:\n",
    "    def __init__(self, file_path, seq_length, batch_size):\n",
    "        self.file_path = file_path\n",
    "        self.seq_length = seq_length\n",
    "        self.batch_size = batch_size\n",
    "        self.data = None\n",
    "        self.K = None\n",
    "        self.char_to_ind = None\n",
    "        self.ind_to_char = None\n",
    "    \n",
    "    def load_data(self):\n",
    "        \"\"\"Prepares all the data necessary to train an RNN\n",
    "        \"\"\"\n",
    "        fid = open(self.file_path, \"r\")\n",
    "        book_data = fid.read()\n",
    "        fid.close()\n",
    "        self.data = book_data\n",
    "        unique_chars = list(set(book_data))\n",
    "        K = len(unique_chars)\n",
    "        self.K = K\n",
    "        mapping_value = np.arange(K)\n",
    "        char_to_ind = dict(zip(unique_chars, mapping_value))\n",
    "        ind_to_char = dict(zip(mapping_value, unique_chars))\n",
    "        self.char_to_ind = char_to_ind\n",
    "        self.ind_to_char = ind_to_char\n",
    "\n",
    "    def get_one_hot_encoding(self, X_chars):\n",
    "        \"\"\"Encodes text as a one hot array\n",
    "\n",
    "        Args:\n",
    "            char_to_ind (dict): the mapping\n",
    "            X_chars (string): characters to encode\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: one-hot encoding\n",
    "        \"\"\"\n",
    "        seq_length = len(X_chars)\n",
    "        one_hot = np.zeros((self.K, seq_length))\n",
    "        for i, char in enumerate(X_chars):\n",
    "            ind = self.char_to_ind[char]\n",
    "            one_hot[ind, i] = 1\n",
    "        return one_hot\n",
    "\n",
    "    def get_decoded_one_hot(self, Y):\n",
    "        \"\"\"Decodes one-hot array back to text\n",
    "\n",
    "        Args:\n",
    "            ind_to_char (dict): the mapping\n",
    "            Y (np.ndarray): one-hot encoding\n",
    "\n",
    "        Returns:\n",
    "            string: the decoded text\n",
    "        \"\"\"\n",
    "        text = ''\n",
    "        for t in range(Y.shape[1]):\n",
    "            char_max = np.argmax(Y[:, t])\n",
    "            text += self.ind_to_char[char_max]\n",
    "        return text\n",
    "\n",
    "    def preprocess(self):\n",
    "        \"\"\"Prepares the data as a tuple of inputs and outputs \n",
    "        \"\"\"\n",
    "        encoded_data = self.get_one_hot_encoding(self.data)\n",
    "        num_sequences = len(self.data) // self.seq_length # discarding the tail\n",
    "        sequences = []\n",
    "        t = 0 # pointer in text\n",
    "        for seq in range(num_sequences):\n",
    "            inputs = encoded_data[:, t: t+self.seq_length]\n",
    "            outputs = encoded_data[:, t+1: t+self.seq_length+1]\n",
    "            sequences.append((inputs, outputs))\n",
    "            t += self.seq_length\n",
    "        return sequences\n",
    " \n",
    "DP = DataPreprocessing(FILE_PATH, SEQ_LENGTH, BATCH_SIZE)\n",
    "DP.load_data()\n",
    "sequences = DP.preprocess()\n",
    "print(len(DP.data))\n",
    "print(DP.K)\n",
    "print(sequences[0][0].shape)\n",
    "print(sequences[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e1c5f0",
   "metadata": {},
   "source": [
    "### Network architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dd67bb",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc771969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ee00673",
   "metadata": {},
   "source": [
    "### Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3362229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "972d0008",
   "metadata": {},
   "source": [
    "### Text synthesis and evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a107588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04a34f15",
   "metadata": {},
   "source": [
    "### Save and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45870dde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
