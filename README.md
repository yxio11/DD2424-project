# DD2424-project
This is a group course project on implementing RNN and LSTM for text generator. The network is based on pytorch and tensorflow structure. Certain tasks on training method (GRU) with different datasets, implementing nucleus sampling method and searching for best parameter is implemented, following with relevant evaluation method. The quantitative metrics used were spelling percentage, term token ratio, perplexity, BLEU score, and BERTScore.

# Main Sections
## Data processing
### Nucleus sampling

### Text synthesize function

## Model built and text synthesize
### Baseline RNN
- Build the network
- Identify the effect when changing the hidden layer
- See the output from the network

### One and two layer LSTM
- Build the network
- Identify the effect when changing the hidden layer
- See the output from the network

### GRU
- Build the network
- Identify the effect when changing the hidden layer
- See the output from the network

## Evaluation
### Perplexity

### Self BLEU

### Zipf distribution analysis (?)

### Evaluation in three models, compare with each other following with the output

## Parameter adjusting
### Grid search 
